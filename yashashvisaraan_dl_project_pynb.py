# -*- coding: utf-8 -*-
"""YashashviSaraan DL project.pynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K10hpSUcBOMcdAqrZPxTBPwoNbdUFM57
"""

#import libraries
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

from sklearn.ensemble import RandomForestClassifier

import seaborn as sb
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_auc_score

from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix

# prompt: import df.csv from my drive

from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv('/content/drive/My Drive/flights.csv')

print(df.head())
print(df.info())



df_needed_data = df[0:100000]

df_needed_data

df_needed_data.value_counts('DIVERTED')

sb.jointplot(data=df_needed_data, x="SCHEDULED_ARRIVAL", y="ARRIVAL_TIME")

from sklearn.preprocessing import LabelEncoder

# Encoding categorical columns
label_encoder = LabelEncoder()
for col in df_needed_data.select_dtypes(include=['object']).columns:
    df_needed_data[col] = label_encoder.fit_transform(df_needed_data[col])

# Recompute the correlation matrix
corr = df_needed_data.corr(method='pearson')

sb.heatmap(corr)

corr

df_needed_data=df_needed_data.drop(['YEAR','FLIGHT_NUMBER','AIRLINE','DISTANCE','TAIL_NUMBER','TAXI_OUT',
                                              'SCHEDULED_TIME','DEPARTURE_TIME','WHEELS_OFF','ELAPSED_TIME',
                                              'AIR_TIME','WHEELS_ON','DAY_OF_WEEK','TAXI_IN','CANCELLATION_REASON'],
                                             axis=1)

df_needed_data

# replacing all NaN values with the mean of the attribute in which they are present
df_needed_data=df_needed_data.fillna(df_needed_data.mean())

df_needed_data

# creating a new column; it will tell if the flight was delayed or not
result=[]

for row in df_needed_data['ARRIVAL_DELAY']:
  if row > 15:
    result.append(1)
  else:
    result.append(0)

df_needed_data['result'] = result
df_needed_data

df_needed_data.value_counts('result')

data = df_needed_data.values
X, y = data[:,:-1], data[:,-1]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

print(df_needed_data.columns)

features = [ 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DAY']

X = df_needed_data[features]

label_encoder = LabelEncoder()
X['ORIGIN_AIRPORT'] = label_encoder.fit_transform(X['ORIGIN_AIRPORT'])
X['DESTINATION_AIRPORT'] = label_encoder.fit_transform(X['DESTINATION_AIRPORT'])

scaler = StandardScaler()
X[['SCHEDULED_DEPARTURE', 'DAY']] = scaler.fit_transform(X[['SCHEDULED_DEPARTURE', 'DAY']])

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
classifiers = {
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "KNN": KNeighborsClassifier()
}

from sklearn.metrics import accuracy_score, classification_report
results = {}
for name, clf in classifiers.items():
    print(f"Training {name}...")
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc
    print(f"Accuracy of {name}: {acc:.2f}")
    print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt

# Plotting the comparison of classifier accuracies
classifier_names = list(results.keys())
accuracies = list(results.values())

plt.figure(figsize=(6, 6))
plt.bar(classifier_names, accuracies, color=['blue', 'green', 'red', 'purple', 'orange'])

# Adding details to the plot
plt.title("Comparison of Classifier Accuracies", fontsize=16)
plt.xlabel("Classifiers", fontsize=14)
plt.ylabel("Accuracy", fontsize=14)
plt.ylim(0, 1)  # Accuracy ranges from 0 to 1
plt.xticks(rotation=45, fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Display the plot
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Compute confusion matrices for all classifiers
confusion_matrices = {}

for name, clf in classifiers.items():
    y_pred = clf.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    confusion_matrices[name] = cm

# Plot confusion matrices
plt.figure(figsize=(15, 10))

for i, (name, cm) in enumerate(confusion_matrices.items(), start=1):
    plt.subplot(2, 3, i)  # Adjust grid size based on number of classifiers
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
    disp.plot(cmap='Blues', ax=plt.gca(), colorbar=False)
    plt.title(name)

plt.tight_layout()
plt.show()

model = Sequential([
    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')  # Output layer for binary classification
])

model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_accuracy:.2f}")

predictions = (model.predict(X_test) > 0.5).astype("int32")